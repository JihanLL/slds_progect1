### 4/22 18:33
- 修改了CNN类的结构，更容易修改网络参数、网络结构。
- train.py 的代码结构做了调整
- 下载了MINST
- 建立models，balance_data, 从MNIST中抽出子数据集；并把接口接入了train.py

### 4/23 13:31
- 增添了一下必要的注释与后续修改的建议
- 对函数test_loop做了调整，使其能够记录错误分类样本
  
### 4/24 17:06
-  添加正则化
-  添加Dropout
-  添加随机种子设定函数
-  添加更多的metrix

# Roadmap
- [x] 3.3.1 搭建CNN模型
- [ ] 3.3.2 比较CNN模型和机器学习模型的性能指标差异
- [ ] 3.3.3 通过实验探究超参数和网络深度、网络结构等对CNN性能的影响
- [ ] 4.1 使用MNIST中的部分数据进行实验
- [ ] 4.2 逐步增加训练数据的数量，每次增加1000至2000张，重新训练和评估模型，记录准确率，召回率等性能指标的变化情况
- [ ] 4.3 重复4.2，但是每次增加的训练数据数量指数级数增长，同时在不同模型上进行实验
- [ ] 5.1 记录各算法分类错误的样本，并在样本降维的可视化中加以体现。分析不同算法分类错误的样本集合的结构
- [ ] 5.2.1 在模型的损失函数中添加L1或L2正则化项，观察不同正则化强度下模型在验证集和测试集上的性能变化
- [ ] 5.2.2 加dropout
- [ ] 5.2.3 对比不同参数量的MLP和CNN，在满minist下train, 观察不同参数量下模型在验证集和测试集上的性能变化
- [ ] bonus 1.1 使用kmeans和kmodiod两种聚类方法对MNIST数据集中的图像样本进行聚类，做可视化
- [ ] bonus 1.2 将同样的聚类方法应用于CNN中的各个卷积层输出（有多个通道的可以进行合并），观察这些卷积层输出的聚类效果与各样本真实标签的一致性变化趋势
- [ ] bonus 2.1 将MNIST图像数据集更换为DDR眼底彩照图像数据集，再跑一遍CNN（及其他模型），观察性能指标是否存在明显的差异。
- [ ] bonus 2.2 对于MNIST上尝试过的各种图像增强方法，在DDR上也进行尝试，观察模型的训练和预测效果
